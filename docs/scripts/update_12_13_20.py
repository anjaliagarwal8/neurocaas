## Update for start of week 12/14
import script_doc_utils

if __name__ == "__main__":
    md = script_doc_utils.initialize_doc({"prev":"update_11_30_20"})
    md.new_header("State of the developer package")
    md.new_paragraph("As of this moment, we now have a minimal working example for the first major chunk of local development code. I have written and tested two modules, `local` and `log`, which interface with docker and handle object logging respectively in order to streamline local workflow. I have used the `local` module to configure a small video configuration package that I wrote for the carcea lab inside a docker container, saved that docker container to an image, and then tested it from the command line, writing outputs to pre-designated log files. This workflow works from the ipython console or (if just running the last testing part) from the command line. Even from this preliminary test run, I have a few comments:")
    md.new_list([
        "The handling of docker volumes seems a little iffy. If your docker volume has a name that is already taken, it will default to having a different name (some sort of long string), and consequently will not be found. *Make sure to search through existing volumes when you instantiate a new local_env to avoid this issue.*",
        "The handling of the bash command that is to be passed to run_analysis is a little iffy. You're appending quotes to the end manually. In general, this command handling looks a little clunky, especially if calling initialize.py from the command line. Let's come up with a cleaner way of handling this command parameter. *Eventually, we want to handle this directly from a blueprint. Then you can print the image tag and the command in relevant fields: this can be found by remote resources, and simplifies your workflow if you can figure out how to handle data parameters. *",
        "You should make sure that the cpu usage and memory usage tracking parameters work properly. As it stands this analysis completes too completely to be sure. ",
        "It's very difficult to access a stopped container in order to examine its state. This is frustrating when we want to debug and we suspect that there is something about having a terminal into the instance will help. It looks like there are hacks around this but they are all pretty unsatisfying. Maybe you can have a command to make the container hang when you want to look at its state afterwards.",
        "The timestamps on individual job logs are somewhat hard to parse, especially if you're running lots of jobs at once. ",
        "We get ugly errors when running in local mode about errors getting the certificate. Handle these and make more soothing things print to the command line, including where users can see job output."
        "It's pretty confusing to have two version of the neurocaas_contrib repo inside and outside the docker container, especially if the script you write only lives on the one inside the container. Figure out a way to make this consistent.",
        "It would be great to have the structure of io-dir match the structure of the user's bucket. In particular, this would mean having outputs go to a timestamped subdirectory instead of into the main directory. The best way to accomplish this might be to pass an environment variable into the docker container (make sure to do this when testing interactively too.)"
        ])
    md.new_paragraph("These questions all have to be decided in the context of the structure of our next steps: the autoscript that we started writing to handle data transfer. One question is: what gets put in the autoscripting fields for inputs? Answer: autoscript will take in paths to locations in a designated localenv as inputs. *It will take care of moving the designated inputs from s3 to these io-dir locations* (should be config or inputs locations), with additional inputs being handled as a parameter in the config file.")
    md.new_paragraph("Of course, the steps that come after this are very important too: making the docker container consistent with what AWS can host on its instances (with the AWS Linux AMI), and working in testing with localstack if we have the time.")
    md.new_list(["[ ] Email Jack about status",
        "[ ] Come up with a workflow figure for what's happening now, and what will be happening after we make the update to version 2.0. This figure will serve two purposes:",["1. It will take care of issue #20: have a figure to explain what's going on now for developers.","2. It will set up Figure 2 updates (issue #30)."],"[ ] Set up some examples of the neurocaas_install_experiments pipeline","[ ] Set up carcealab pipeline with our new workflow (hosted on AWS instance)"])
